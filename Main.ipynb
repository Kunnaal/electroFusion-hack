{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f82473",
   "metadata": {},
   "source": [
    "# Lane Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c882ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from jetbot import Robot\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model.load_state_dict(torch.load('LaneDetection/LaneDetection.pth'))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "camera = Camera()\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last\n",
    "    image = change['new']\n",
    "    xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "execute({'new': camera.value})\n",
    "\n",
    "camera.observe(execute, names='value')\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c2216",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "model = r\"ObjectDetection/ObjectDetection.h5\"    # Path for the model\n",
    "test_file = r\"\"   # Path for the image to be tested\n",
    "label = [\"Person\", \"Animal\", \"Stop\", \"Cones\", \"RedLight\", \"BlueLight\", \"GreenLight\", \"None\", \"Zebra\"]\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = load_model(model)\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "# Replace this with the path to your image\n",
    "image = Image.open(test_file)\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "result = np.where(prediction[0] == np.amax(prediction[0]))\n",
    "print(\"\\nPrediction:\", label[result[0][0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
